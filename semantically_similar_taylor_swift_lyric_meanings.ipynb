{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLeS/waq95dFgenC3fYkUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniezhang2288/python_notebooks/blob/main/semantically_similar_taylor_swift_lyric_meanings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nU517Q805uZ",
        "outputId": "9bccb4f2-0973-4c84-8cf0-7fe186aacac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=f1871364c35a9142c4b7111a21ce2f000d56b6365bacd85555aed825ac6e898b\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukQZ-Md10tlX",
        "outputId": "5ef06494-538d-42c2-ef16-c3dddb99af56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 songs related to happy:\n",
            "Back To December by Taylor Swift from the album 'Speak Now': 0.22548998892307281\n",
            "Cold as You by Taylor Swift from the album 'Taylor Swift': 0.18939611315727234\n",
            "Stay Stay Stay by Taylor Swift from the album 'Red': 0.17992272973060608\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Function to find top 3 semantically similar songs\n",
        "def find_top_songs(input_phrase, csv_file, top_n=3):\n",
        "    # Load the dataset with specified encoding\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Alternative encoding\n",
        "\n",
        "    # Pre-trained model for embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Prepare a dictionary to hold similarity scores\n",
        "    song_similarity = {}\n",
        "\n",
        "    # Group by song\n",
        "    grouped = df.groupby(['track_title', 'album', 'artist'])\n",
        "\n",
        "    for name, group in grouped:\n",
        "        # Combine lines into one string per song\n",
        "        lyrics = ' '.join(group['lyric'].tolist())\n",
        "\n",
        "        # Encode lyrics and the input phrase\n",
        "        lyrics_embedding = model.encode(lyrics, convert_to_tensor=True)\n",
        "        input_embedding = model.encode(input_phrase, convert_to_tensor=True)\n",
        "\n",
        "        # Calculate similarity\n",
        "        similarity = util.pytorch_cos_sim(input_embedding, lyrics_embedding)\n",
        "\n",
        "        # Store the score with song details\n",
        "        song_similarity[name] = similarity.item()\n",
        "\n",
        "    # Sort songs by similarity score\n",
        "    sorted_songs = sorted(song_similarity.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top N songs\n",
        "    return sorted_songs[:top_n]\n",
        "\n",
        "# Example usage\n",
        "input_phrase = \"happy\"\n",
        "csv_file = '/content/taylor_swift_lyrics (1).csv'\n",
        "print(\"Top 3 songs related to \" + input_phrase + \":\")\n",
        "top_songs = find_top_songs(input_phrase, csv_file)\n",
        "for song, score in top_songs:\n",
        "    print(f\"{song[0]} by {song[2]} from the album '{song[1]}': {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Function to find top 3 semantically similar songs and their unique top 3 lines with song line numbers\n",
        "def find_top_songs_and_unique_lyrics(input_phrase, csv_file, top_n=3):\n",
        "    # Load the dataset with specified encoding\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Alternative encoding\n",
        "\n",
        "    # Pre-trained model for embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Prepare a dictionary to hold similarity scores for songs\n",
        "    song_similarity = {}\n",
        "\n",
        "    # Group by song\n",
        "    grouped = df.groupby(['track_title', 'album', 'artist'])\n",
        "\n",
        "    for name, group in grouped:\n",
        "        # Reset index for easier row access\n",
        "        group = group.reset_index(drop=True)\n",
        "\n",
        "        # Combine lines into one string per song\n",
        "        lyrics = ' '.join(group['lyric'].tolist())\n",
        "\n",
        "        # Encode lyrics and the input phrase\n",
        "        lyrics_embedding = model.encode(lyrics, convert_to_tensor=True)\n",
        "        input_embedding = model.encode(input_phrase, convert_to_tensor=True)\n",
        "\n",
        "        # Calculate similarity for the whole song\n",
        "        song_similarity_score = util.pytorch_cos_sim(input_embedding, lyrics_embedding).item()\n",
        "\n",
        "        # Calculate similarity for each line\n",
        "        line_embeddings = model.encode(group['lyric'].tolist(), convert_to_tensor=True)\n",
        "        line_similarities = util.pytorch_cos_sim(input_embedding, line_embeddings).flatten()\n",
        "\n",
        "        # Find unique top 3 lines with song line numbers\n",
        "        top_lines = []\n",
        "        top_lines_scores = []\n",
        "        top_line_numbers = []\n",
        "        line_number = 1  # Initialize line number counter\n",
        "        for index in line_similarities.argsort(descending=True).tolist():\n",
        "            if len(top_lines) < 3:\n",
        "                line = group['lyric'].iloc[index]\n",
        "                if line not in top_lines:\n",
        "                    top_lines.append(line)\n",
        "                    top_lines_scores.append(line_similarities[index].item())\n",
        "                    top_line_numbers.append(line_number)\n",
        "                line_number += 1  # Increment line number\n",
        "            if len(top_lines) == 3:\n",
        "                break\n",
        "\n",
        "        # Store the score with song details, top lines, and line numbers\n",
        "        song_similarity[name] = (song_similarity_score, top_lines, top_lines_scores, top_line_numbers)\n",
        "\n",
        "    # Sort songs by similarity score\n",
        "    sorted_songs = sorted(song_similarity.items(), key=lambda x: x[1][0], reverse=True)\n",
        "\n",
        "    # Return top N songs and their top lines with song line numbers\n",
        "    return sorted_songs[:top_n]\n",
        "\n",
        "# Example usage\n",
        "input_phrase = \"happy\"\n",
        "csv_file = '/content/taylor_swift_lyrics (1).csv'\n",
        "print(\"Top 3 songs related to '\" + input_phrase + \"':\")\n",
        "top_songs = find_top_songs_and_unique_lyrics(input_phrase, csv_file)\n",
        "for song, (score, lines, line_scores, line_numbers) in top_songs:\n",
        "    print(f\"{song[0]} by {song[2]} from the album '{song[1]}': {score}\")\n",
        "    print(\"  Top 3 unique lines:\")\n",
        "    for line, line_score, line_number in zip(lines, line_scores, line_numbers):\n",
        "        print(f\"    Line {line_number}: {line} (Score: {line_score})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMMGs_F49hJV",
        "outputId": "09961650-76ca-4c14-bfa0-9074e83b043e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 songs related to 'happy':\n",
            "Back To December by Taylor Swift from the album 'Speak Now': 0.22548998892307281\n",
            "  Top 3 unique lines:\n",
            "    Line 1: I miss your tan skin, your sweet smile, so good to me, so right (Score: 0.3266279101371765)\n",
            "    Line 2: Wishing I'd realized what I had when you were mine (Score: 0.28460580110549927)\n",
            "    Line 5: Realized I loved you in the fall (Score: 0.28333982825279236)\n",
            "Cold as You by Taylor Swift from the album 'Taylor Swift': 0.18939611315727234\n",
            "  Top 3 unique lines:\n",
            "    Line 1: Every smile you fake is so condescending (Score: 0.31048160791397095)\n",
            "    Line 2: Of a mess of a dreamer with the nerve to adore you (Score: 0.2875947654247284)\n",
            "    Line 3: And I stood there loving you and wished them all away (Score: 0.27248454093933105)\n",
            "Stay Stay Stay by Taylor Swift from the album 'Red': 0.17992272973060608\n",
            "  Top 3 unique lines:\n",
            "    Line 1: I've been loving you for quite some time, time, time (Score: 0.2907577157020569)\n",
            "    Line 5: I'd like to hang out with you, for my whole life (Score: 0.289613276720047)\n",
            "    Line 6: Stay, and I'll be loving you for quite some time (Score: 0.2757136821746826)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60wbBcDu_AYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}